{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMeq6Hfv/FqSJCurLc2QGn3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osullik/ic23050/blob/main/DataDictionary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "QRIK9KJvKAYy"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import json\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DD = pd.ExcelFile(\"https://github.com/osullik/ic23050/blob/main/L4%20Washington%20Fatal%20Crash%20Files%20-%20Washington%20Traffic%20Safety%20Commission/DataDictionary_Washington%20Fatal%20Crash%20Files.xlsx?raw=true\")"
      ],
      "metadata": {
        "id": "ODDvNGVaMsMT"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sheet in DD.sheet_names:\n",
        "  print(sheet)\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1KCLmNYNaeo",
        "outputId": "dc70327d-bde0-42e0-b72e-ca9a33d8da67"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ReadMe\n",
            "CRASH Data Files\n",
            "PERSON Data Files\n",
            "Tables1\n",
            "Tables2\n",
            "Tables3\n",
            "Tables4\n",
            "Tables5\n",
            "Tables6\n",
            "Tables7\n",
            "Tables8\n",
            "Tables9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Seperate out each sheet in the data dictionary \n",
        "ReadMe = pd.read_excel(DD, 'ReadMe')\n",
        "CrashDataFiles = pd.read_excel(DD, 'CRASH Data Files')\n",
        "PersonDataFiles = pd.read_excel(DD, 'PERSON Data Files')\n",
        "#Tables1 = pd.read_excel(DD, 'Tables1')\n",
        "Tables2 = pd.read_excel(DD, 'Tables2')\n",
        "Tables3 = pd.read_excel(DD, 'Tables3')\n",
        "Tables4 = pd.read_excel(DD, 'Tables4')\n",
        "Tables5 = pd.read_excel(DD, 'Tables5')\n",
        "Tables6 = pd.read_excel(DD, 'Tables6')\n",
        "Tables7 = pd.read_excel(DD, 'Tables7')\n",
        "Tables8 = pd.read_excel(DD, 'Tables8')\n",
        "Tables9 = pd.read_excel(DD, 'Tables9')"
      ],
      "metadata": {
        "id": "QLH2YtCYNrOL"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "getKVPairs is a function to extract KV Pairs from dirty excel data\n",
        "  Input Args:\n",
        "    desc: a String \"description\" of the values we want to extract. Should \n",
        "      include target KV pairs in the form KEY=VALUE where KEY is a number and \n",
        "      VALUE are non-numeric substrings. \n",
        "  Method: \n",
        "    Break the string into characters\n",
        "    Accumulate numeric values until an \"=\" is seen. The \"=\" is an assignment  \n",
        "      we infer the numbers prior are the key and this is appended to keyList\n",
        "    Accumulate characters until either EOF or another numerical value is found\n",
        "      we infer all strings between keys are their associated values. \n",
        "    \n",
        "    Before appending a value to the definition list, remove newline and \n",
        "      truncate spaces\n",
        "\n",
        "    Zip the KeyList and DefinitionList together, and return\n",
        "\n",
        "  Returns:\n",
        "    A list of Tuples in the form [(Key, Value)]\n",
        "\n",
        "'''\n",
        "def getKVPairs(desc):\n",
        "                                                #Init Vars\n",
        "  number = \"\"\n",
        "  definition = \"\"\n",
        "  keyList = []\n",
        "  definitionList = []\n",
        "  keyFound = False\n",
        "                                                #Filter out non-strings\n",
        "  if type(desc) == str:\n",
        "    for char in desc:\n",
        "      \n",
        "      if char.isnumeric() == True:              #Build the Keys\n",
        "        if keyFound == True:\n",
        "          definition = definition.strip(\"\\n\")\n",
        "          definition = definition.strip()\n",
        "          definitionList.append(definition)\n",
        "          definition = \"\"\n",
        "          keyFound = False\n",
        "          number += char\n",
        "\n",
        "        else:                                   #Build the Values\n",
        "          number += char\n",
        "\n",
        "      elif char == (\"=\"):                       #Commit the Key\n",
        "        keyList.append(number)\n",
        "        number = \"\"\n",
        "        keyFound = True\n",
        "\n",
        "      else:                                     #Build the value\n",
        "        definition += char \n",
        "    else:\n",
        "      pass\n",
        "                                                #Add the last Definition\n",
        "    definition = definition.strip(\"\\n\")\n",
        "    definition = definition.strip()\n",
        "    definitionList.append(definition)\n",
        "\n",
        "  toReturn = list(zip(keyList,definitionList))  #Create a list of (K,V) Tuples\n",
        "\n",
        "  return(toReturn)    "
      ],
      "metadata": {
        "id": "S3GvxIrQ4eZa"
      },
      "execution_count": 321,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parse the CrashDataFile into JSON\n",
        "dataDict = defaultdict(dict)                    #Build the Data Dictionary\n",
        "\n",
        "for idx, series in CrashDataFiles.iterrows():   #Step through each var in turn\n",
        "  var = series['VARIABLE']\n",
        "  typ = series['TYPE']\n",
        "  length = series['LENGTH']\n",
        "  format = series['FORMAT']\n",
        "  label = series['LABEL']\n",
        "  desc = series['DESCRIPTION/COMMENT']\n",
        "\n",
        "                                                #Populate the Data Dictionary\n",
        "  dataDict[var][\"TYPE\"]     = typ\n",
        "  dataDict[var][\"LENGTH\"]   = length \n",
        "  dataDict[var][\"FORMAT\"]   = format \n",
        "  dataDict[var][\"LABEL\"]    = label \n",
        "\n",
        "  kvPairList = getKVPairs(desc)                 #Get list (K,V) tuples for DATA\n",
        "\n",
        "  dataDict[var][\"DATA\"]    = dict(kvPairList)\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "nQxe6TC1NrVs"
      },
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create JSON object out of CrashFileData\n",
        "json_CrashDataFile = json.dumps(dataDict, indent = 4) "
      ],
      "metadata": {
        "id": "0QiwT_R2Ph9R"
      },
      "execution_count": 428,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parse the PersonDataFile into JSON\n",
        "dataDict_PersonData = defaultdict(dict)                    #Build the Data Dictionary\n",
        "\n",
        "print(PersonDataFiles.columns)\n",
        "\n",
        "for idx, series in PersonDataFiles.iterrows():   #Step through each var in turn\n",
        "  var = series['VARIABLE']\n",
        "  typ = series['TYPE']\n",
        "  length = series['LENGTH']\n",
        "  format = series['FORMAT']\n",
        "  label = series['LABEL']\n",
        "  desc = series['DESCRIPTION/COMMENT']\n",
        "\n",
        "                                                #Populate the Data Dictionary\n",
        "  dataDict_PersonData[var][\"TYPE\"]     = typ\n",
        "  dataDict_PersonData[var][\"LENGTH\"]   = length \n",
        "  dataDict_PersonData[var][\"FORMAT\"]   = format \n",
        "  dataDict_PersonData[var][\"LABEL\"]    = label \n",
        "\n",
        "  kvPairList = getKVPairs(desc)                 #Get list (K,V) tuples for DATA\n",
        "\n",
        "  dataDict_PersonData[var][\"DATA\"]    = dict(kvPairList)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mowbCCllPr2m",
        "outputId": "88e29c27-3840-4b0b-9ef3-2155ae6ff9b6"
      },
      "execution_count": 375,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'VARIABLE', 'TYPE', 'LENGTH', 'FORMAT', 'LABEL',\n",
            "       'DESCRIPTION/COMMENT', 'Notes / SAS Code', 'Unnamed: 8', 'Unnamed: 9'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create JSON object out of PersonFileData\n",
        "json_PersonDataFile = json.dumps(dataDict_PersonData, indent = 4) "
      ],
      "metadata": {
        "id": "oA5vfD1iPr63"
      },
      "execution_count": 429,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract the messy table data from the TABLES1 Sheet \n",
        "  #(Manual inspection used to determine the cut points for the DFs)\n",
        "Tables1_county = pd.read_excel(DD, 'Tables1', skiprows = 1, nrows=40,  usecols= 'A')\n",
        "Tables1_harmfulEvent = pd.read_excel(DD, 'Tables1', skiprows = 1, nrows=40,  usecols= 'B,D')\n",
        "Tables1_trafficControl = pd.read_excel(DD, 'Tables1', skiprows = 42, nrows=20,  usecols= 'A,D')\n",
        "Tables1_seatingPosition = pd.read_excel(DD, 'Tables1', skiprows = 0, nrows=31,  usecols= 'E')\n"
      ],
      "metadata": {
        "id": "WREnT1qpPsDc"
      },
      "execution_count": 431,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parse out the County Numbering System\n",
        "dataDict_Table1 = defaultdict(dict)                    #Build the Data Dictionary\n",
        "\n",
        "#print(Tables1_county.columns)\n",
        "dataDict_Table1[\"County_Name\"][\"DATA\"] = {}\n",
        "\n",
        "for idx, series in Tables1_county.iterrows():   #Step through each var in turn\n",
        "  \n",
        "  desc = series['county_char']\n",
        "\n",
        "  kvPairList = getKVPairs(desc)                 #Get list (K,V) tuples for DATA\n",
        "  kvPairTuple = tuple(kvPairList[0])\n",
        "\n",
        "  dataDict_Table1[\"County_Name\"][\"DATA\"][kvPairTuple[0]] = kvPairTuple[1]"
      ],
      "metadata": {
        "id": "KvhW7AipPsHe"
      },
      "execution_count": 432,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parse out the Harmful Event Data from Table1\n",
        "\n",
        "dataDict_Table1[\"Harmful_Event\"][\"DATA\"] = {}\n",
        "\n",
        "for idx, series in Tables1_harmfulEvent.iterrows():   #Step through each var in turn\n",
        "  \n",
        "  desc1 = series['Non-Collision']\n",
        "  desc2 = series['Unnamed: 3']\n",
        "\n",
        "  kvPairList1 = getKVPairs(desc1)                 #Get list (K,V) tuples for DATA\n",
        "  kvPairList2 = getKVPairs(desc2)\n",
        "\n",
        "\n",
        "  #Following try/catch statements account for misalignment of columns in \n",
        "  #input data\n",
        "  try:                                            #Transform into tuples\n",
        "    kvPairTuple1 = tuple(kvPairList1[0])\n",
        "  except IndexError:\n",
        "    pass\n",
        "\n",
        "  try:\n",
        "    kvPairTuple2 = tuple(kvPairList2[0])\n",
        "  except IndexError:\n",
        "    pass\n",
        "\n",
        "  try:                                           #Update the Dicts\n",
        "    dataDict_Table1[\"Harmful_Event\"][\"DATA\"][kvPairTuple1[0]] = kvPairTuple1[1]\n",
        "  except NameError:\n",
        "    pass\n",
        "  try:\n",
        "    dataDict_Table1[\"Harmful_Event\"][\"DATA\"][kvPairTuple2[0]] = kvPairTuple2[1]\n",
        "  except NameError:\n",
        "    pass"
      ],
      "metadata": {
        "id": "Ofy--07EPsOQ"
      },
      "execution_count": 423,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parse out the Traffic Control Data from Table1\n",
        "\n",
        "dataDict_Table1[\"Traffic_Control\"][\"DATA\"] = {}\n",
        "\n",
        "for idx, series in Tables1_trafficControl.iterrows():   #Step through each var in turn\n",
        "  \n",
        "  desc1 = series['TRAFFIC CONTROL DEVICE']\n",
        "  desc2 = series['Unnamed: 3']\n",
        "\n",
        "  kvPairList1 = getKVPairs(desc1)                 #Get list (K,V) tuples for DATA\n",
        "  kvPairList2 = getKVPairs(desc2)\n",
        "\n",
        "  #Following try/catch statements account for misalignment of columns in \n",
        "  #input data\n",
        "  try:                                            #Transform into tuples\n",
        "    kvPairTuple1 = tuple(kvPairList1[0])\n",
        "  except IndexError:\n",
        "    pass\n",
        "\n",
        "  try:\n",
        "    kvPairTuple2 = tuple(kvPairList2[0])\n",
        "  except IndexError:\n",
        "    pass\n",
        "\n",
        "  try:                                           #Update the Dicts\n",
        "    dataDict_Table1[\"Traffic_Control\"][\"DATA\"][kvPairTuple1[0]] = kvPairTuple1[1]\n",
        "  except NameError:\n",
        "    pass\n",
        "  try:\n",
        "    dataDict_Table1[\"Traffic_Control\"][\"DATA\"][kvPairTuple2[0]] = kvPairTuple2[1]\n",
        "  except NameError:\n",
        "    pass"
      ],
      "metadata": {
        "id": "6S8joujnY4g6"
      },
      "execution_count": 425,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parse out the Seating Positions\n",
        "dataDict_Table1[\"Seating_Position\"][\"DATA\"] = {}\n",
        "\n",
        "for idx, series in Tables1_seatingPosition.iterrows():   #Step through each var in turn\n",
        "  \n",
        "  desc = series['SEATING POSITION']\n",
        "\n",
        "  kvPairList = getKVPairs(desc)                 #Get list (K,V) tuples for DATA\n",
        "  try:\n",
        "    kvPairTuple = tuple(kvPairList[0])\n",
        "    dataDict_Table1[\"Seating_Position\"][\"DATA\"][kvPairTuple[0]] = kvPairTuple[1]\n",
        "  except IndexError:\n",
        "    pass"
      ],
      "metadata": {
        "id": "9WKk5wImbHF3"
      },
      "execution_count": 426,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a JSON object of the Table1 Data\n",
        "json_Table1 = json.dumps(dataDict_Table1, indent = 4) "
      ],
      "metadata": {
        "id": "VQW5rCcicHjP"
      },
      "execution_count": 433,
      "outputs": []
    }
  ]
}